from pathlib import Path

# Project paths
PROJECT_ROOT = Path(__file__).parent.parent
LOGS_DIR = PROJECT_ROOT / "logs"
DATASETS_DIR = PROJECT_ROOT / "datasets"
MODELS_DIR = PROJECT_ROOT / "models"
OUTPUTS_DIR = PROJECT_ROOT / "outputs"

# Model defaults
DEFAULT_H_DIM = 384
DEFAULT_N_HEAD = 8
DEFAULT_TIME_DIM = 1280
DEFAULT_EMBEDDING_DIM = 320
DEFAULT_CONTEXT_DIM = 512
GROUPNORM_GROUPS = 32

# Latent space dimensions
DEFAULT_LATENT_CHANNELS = 4
DEFAULT_LATENT_HEIGHT = 4
DEFAULT_LATENT_WIDTH = 4

# Training defaults
DEFAULT_SEED = 42
DEFAULT_BATCH_SIZE = 4
DEFAULT_LEARNING_RATE = 1e-4
DEFAULT_WEIGHT_DECAY = 0.01
DEFAULT_ETA_MIN = 1e-5
DEFAULT_EPOCHS = 50
DEFAULT_SAVE_EVERY = 10
DEFAULT_LOG_EVERY = 5
DEFAULT_MAX_CHECKPOINTS = 5

# Data processing
DEFAULT_IMAGE_SIZE = (32, 32)
DEFAULT_TRAIN_SPLIT = 0.8
DEFAULT_NUM_WORKERS = 4
DEFAULT_PIN_MEMORY = True
DEFAULT_PERSISTENT_WORKERS = True

# Diffusion defaults
DEFAULT_NUM_TRAIN_TIMESTEPS = 1000
DEFAULT_BETA_START = 0.00085
DEFAULT_BETA_END = 0.012
DEFAULT_SCALING_FACTOR = 0.18215
DEFAULT_NUM_INFERENCE_STEPS = 50
DEFAULT_GUIDANCE_SCALE = 7.5

# Time embedding constants
TIME_EMBEDDING_FREQ_BASE = 10000
TIME_EMBEDDING_MULTIPLIER = 4

# Model identifiers
CLIP_MODEL_ID = "openai/clip-vit-base-patch32"
VAE_MODEL_ID = "stabilityai/sd-vae-ft-mse"
CLIP_MAX_LENGTH = 77

# Logging
DEFAULT_LOGGER_NAME = "emo_generator"
LOG_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
DATE_FORMAT = "%Y-%m-%d"

# File extensions
CHECKPOINT_EXT = ".pt"
CONFIG_EXT = ".yaml"
LOG_EXT = ".log"
IMAGE_EXT = ".png"

# MLflow
MLFLOW_CANDIDATE_ALIAS = "candidate"
MLFLOW_CHALLENGER_ALIAS = "challenger"
MLFLOW_CHAMPION_ALIAS = "champion"
